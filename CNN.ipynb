{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOXpqRAGR23ydIJ3jQ0EWDl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pxs1990/Data_Science_projects/blob/main/CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Convolutional Neural Network:**\n",
        "A Convolutional Neural Network (CNN) is a type of artificial neural network specifically designed for processing structured grid data, such as images or sequences. CNNs have proven to be highly effective in tasks related to computer vision, such as image classification, object detection, and image segmentation. The key idea behind CNNs is the use of convolutional layers to automatically and adaptively learn spatial hierarchies of features from the input data.\n",
        "\n",
        "Here are some key components and concepts associated with Convolutional Neural Networks:\n",
        "\n",
        "1. **Convolutional Layers:** These layers apply convolutional operations to the input data, which involves sliding a filter (also known as a kernel) across the input to extract local patterns. The learned filters detect features like edges, textures, or more complex structures in the input.\n",
        "\n",
        "2. **Pooling Layers:** After convolutional layers, pooling layers are often used to downsample(reduce) the spatial dimensions(pixel) of the input, reducing the computational complexity and the number of parameters in the network. Common pooling operations include max pooling(pooling max from each chunk from original data and is done by kernel) and average pooling. he stride is the step size at which the kernel moves across the input data during the convolutional operation.\n",
        "\n",
        "3. **Activation Functions:** Non-linear activation functions, such as ReLU (Rectified Linear Unit), are applied after convolutional and pooling layers to introduce non-linearity to the model. This allows the network to learn more complex relationships in the data.\n",
        "\n",
        "4. **Fully Connected Layers:** In addition to convolutional layers, CNNs typically include one or more fully connected layers towards the end of the network. These layers connect every neuron to every neuron in the previous and subsequent layers, enabling the network to make decisions based on the learned features.\n",
        "\n",
        "5. **Flattening:** Before the fully connected layers, the output from the convolutional and pooling layers is flattened into a one-dimensional vector. This vector is then fed into the fully connected layers for classification or regression.\n",
        "\n",
        "6. **Dropout:** Dropout is a regularization technique commonly applied to CNNs. It randomly drops a fraction of neurons during training, preventing overfitting and improving the generalization of the model.\n",
        "\n",
        "7. **Batch Normalization:** This technique normalizes the input of each layer, helping with training stability and accelerating convergence.\n",
        "\n",
        "Convolutional Neural Networks have been instrumental in achieving state-of-the-art performance in various computer vision tasks, and their architecture has been adapted and extended for other types of data, such as time-series and audio data, with modifications like 1D convolutions."
      ],
      "metadata": {
        "id": "JimYZT9rykJY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YryQAi_DptHc"
      },
      "outputs": [],
      "source": [
        "# for i in range(0,12000,64):\n",
        "#     for j in range(0,12000,64):\n",
        "#         print('size of image', i, 'X', j, 'is:',i*j*3)\n",
        "# #Size of image last is almost 500M, so we need CNN"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#create shortcut of dataset shared in gdrive\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "tf.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "OGS-7x5nyrx4",
        "outputId": "1c33355e-9b6b-4f68-eca6-0d5fc4b84430"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.15.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RMX798zB8f_4",
        "outputId": "3570fa91-743e-41b2-b524-16e4ea7c2bbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Part 1 - Data Preprocessing**"
      ],
      "metadata": {
        "id": "sQcnEumZATvP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preprocessing the Training set**"
      ],
      "metadata": {
        "id": "VdODfBRuAXT2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "training_set = train_datagen.flow_from_directory('/content/gdrive/MyDrive/Dataset/CNNdataset/training_set',\n",
        "                                                 target_size = (64, 64),\n",
        "                                                 batch_size = 32,\n",
        "                                                 class_mode = 'binary')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-p3W-QQeAevN",
        "outputId": "1c6fe34f-15df-43f1-943b-272909b984db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 8000 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preprocessing the Test set**"
      ],
      "metadata": {
        "id": "7U4aKc2YBCw3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "test_set = test_datagen.flow_from_directory('/content/gdrive/MyDrive/Dataset/CNNdataset/test_set',\n",
        "                                            target_size = (64, 64),\n",
        "                                            batch_size = 32,\n",
        "                                            class_mode = 'binary')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efkbxKPBBDx3",
        "outputId": "70059510-f281-4235-d7c8-d592f8010842"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2000 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Part 2 - Building the CNN**"
      ],
      "metadata": {
        "id": "ug-ekP_QHaLZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Initialising the CNN**"
      ],
      "metadata": {
        "id": "2ZoDAahwHg4X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn = tf.keras.models.Sequential()"
      ],
      "metadata": {
        "id": "834eRdXIHlGH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step 1 - Convolution**"
      ],
      "metadata": {
        "id": "2dMT0CmTHooy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[64, 64, 3]))"
      ],
      "metadata": {
        "id": "__kBCURnHrEI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step 2 - Pooling**"
      ],
      "metadata": {
        "id": "mK5BCEzmHsqx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
      ],
      "metadata": {
        "id": "nLoRK-7VHtvB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Adding a second convolutional layer**"
      ],
      "metadata": {
        "id": "vZm9E4Y9HxQY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
      ],
      "metadata": {
        "id": "rPojYZjhH0Ts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step 3 - Flattening**"
      ],
      "metadata": {
        "id": "-QDFfkywH2xP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Flatten())"
      ],
      "metadata": {
        "id": "g2xFU0KMH4l4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step 4 - Full Connection**"
      ],
      "metadata": {
        "id": "LpCvMQs8H7E3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))"
      ],
      "metadata": {
        "id": "hGscfVU0H9eo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step 5 - Output Layer**"
      ],
      "metadata": {
        "id": "FxeFB8CmIBqG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "wa3FpFHnIEMA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Part 3 - Training the CNN**"
      ],
      "metadata": {
        "id": "di8V9NpIIHWC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Compiling the CNN**"
      ],
      "metadata": {
        "id": "oZ7p3xJ4IKH-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "-CAnfIUBIIun"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Training the CNN on the Training set and evaluating it on the Test set**"
      ],
      "metadata": {
        "id": "UBHyJMV7IQ8_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.fit(x = training_set, validation_data = test_set, epochs = 5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Jw9MmgKISnu",
        "outputId": "299e2391-ed6c-40a3-c2b3-bdc12c32bd73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "117/250 [=============>................] - ETA: 13:31 - loss: 0.6960 - accuracy: 0.5312"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Making the Prediction**"
      ],
      "metadata": {
        "id": "W0eRikN637Mw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "test_image = image.load_img('/content/gdrive/MyDrive/CNNdataset/training_set/cats/cat.1002.jpg', target_size = (64, 64))\n",
        "test_image = image.img_to_array(test_image)\n",
        "test_image = np.expand_dims(test_image, axis = 0)\n",
        "result = cnn.predict(test_image)\n",
        "training_set.class_indices\n",
        "if result[0][0] == 1:\n",
        "  prediction = 'dog'\n",
        "else:\n",
        "  prediction = 'cat'"
      ],
      "metadata": {
        "id": "nsKmqNm633hH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(prediction)"
      ],
      "metadata": {
        "id": "Ph2CFE5F4FBk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}